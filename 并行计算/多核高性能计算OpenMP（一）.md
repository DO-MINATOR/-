## 并行计算概论

现代计算，求解问题的规模不断扩大，硬件性能不断提升，人们希望通过使用多颗CPU来完成同一个任务，这就是并行计算的由来。

多核处理器利用在一个芯片上集成多个核心，可以对外提供统一服务，具有如下优点：

1. 多个CPU核心可以成倍的提高整个处理器执行的线程数量，从而提升整体性能。
2. 多个核心集成在一个芯片上，极大缩短互连线，降低了通信延时。
3. 多核CPU共享芯片上的资源，实现核心间的数据交互。

与分布式计算不同的是，并行计算注重将问题划分为多个子问题求解，粒度较细，并行程度高，且计算过程中需频繁的交换数据。分布式计算粒度粗，注重的是任务的长时间运行，多以事务型计算为主。

## 并行计算种类划分

### CPU与存储器的连接方式

- 共享存储系统，所有CPU通过总线相连，共用存储器和I/O设备。典型代表：实验室服务器。
- 分布式存储系统，多台节点依赖专用通信网络连接。典型代表：服务器集群。

### 数据通信方式

- 共享地址型，对应于共享存储系统。
- 消息传递型，对应于分布式存储系统。

### 指令和数据的工作方式

- SISD（single instruction single data）：单指令单数据流。
- SIMD（single instruction multiple data）：单指令多数据流，GPU执行多为SIMD。
- MISD：实际作业中不会采用。
- MIMD：多指令多数据流，即不同CPU执行不同指令，输入不同数据。

## 并行编程模式

消息传递型多采用MPI（Message Passing Interface）编程，共享地址型采用OpenMP（Open Multi-Processing）编程。OpenMP多应用在个人计算机，编程模型简单，扩展性和可移植性强，因此后续学习以OpenMP开头。

一个串行程序修改成并行程序后，需保证正确性、高性能、可扩展（不应依赖于具体CPU参数）。

OpenMP是一种基于数据并行的编程模式，即将相同的操作同时作用于不同的数据，符合SIMD，这种计算常见于CPU。CPU不但擅长指令运算，而且擅长各类数值运算，GPU仅擅长数值运算。

1）微架构层面上，CPU同时兼顾“指令运算”和“数据运算”，因此设计上要考量加法器、控制器以及各类逻辑线路，这种复杂性不能仅以晶体管的数量来衡量，同时也来自于实现诸如2程序分支预测、推测执行、多重嵌套等。而GPU的“指令运算”成分较少，多具备许多相同的运算单元，适合同时执行大量相同的函数计算。尽管晶体管数量很多，但设计较CPU简单。

2）主频方面，目前主流的CPU频率可达3~4GHz，而GPU大都停留在1~2GHz，GPU的优势主要在于浮点运算，来源于其具备的大量并行的计算单元，但这种计算单元对于程序的逻辑执行较为无力。

3）IPC，控制指令上，CPU高于GPU，数据指令上，GPU高于CPU。

GPU的执行标准有OpenCL和CUDA，执行任务主要为无逻辑关系的大量平行数据的并行计算。

## 并行算法评价

并行加速比，ts是串行执行时间，tp是并行执行时间。二者相除得到加速比，理论上该值应为CPU核心数量n（一核心双线程认为是两个核心），但由于一些开销（线程建立、销毁，程序间的通信、同步因素，竞争资源等），导致该值小于n。
$$
R_s=\frac{t_s}{t_p}
$$

但是，Rs有可能会大于n，这种情况称为超线性加速，由于CPU访问数据是优先读取高速缓存，而高速缓存容量比内存小，如果读取的数据量较大，就会频繁的刷新缓存数据，并行情况下，这种刷新过程也被并行化，相当于是串行刷新缓存的次数减少了，这时，并行加速比会大于n。

## OpenMP多核编程

下述情况，应尽可能考虑使用OpenMP编程。

1. 计算平台是多核CPU，且单个CPU的计算能力已被发掘殆尽。
2. 程序需要跨平台，OpenMP通过编译指导语句实现程序并行化，即只要节点有OpenMP编译环境，就可以执行。
3. 循环计算是计算瓶颈，OpenMP主要针对循环进行优化，如果程序循环间没有依赖，就可以实现循环优化。
4. 不想大幅度修改源代码，OpenMP包括编译指导语句、库函数和环境变量，针对源代码改动较小。

OpenMP对并行的高层抽象简化了并行编程的难度和实现细节，但是不适用于需要复杂的线程间同步和互斥的场合（数据依赖、同步和互斥需要编程人员自己考虑），也不适用于消息传递系统。