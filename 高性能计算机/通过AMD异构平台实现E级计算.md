### 摘要

AMD的E级计算前景，提出了软硬件协同计算的挑战，和当前做出的努力

### 绪论

第一台P级（10^15^）超算机在2008年实现，截至2020年6月，最快的超算Fugaku的峰值运行速度达到513.854*10^15^次浮点运算，这些高性能计算系统执行大量的计算，以推动重要的科学实验，从而设计出更高效的燃料和发动机，更安全的桥梁和建筑，从模拟全球气候，到探索宇宙的起源，超算发挥了越来越重要的作用。下一代将要实现的是E级（10^18^）浮点运算，包含100000个互联的计算节点，平均每个计算节点需实现10T（10^13^）次浮点运算，但现代的高端显卡计算速度最多达到该目标的2/3。

目前的挑战在于，系统的内存容量、传输速率、电源功率必须提高几个数量级，另外节点数量众多，因此还要保证系统的可靠性和可扩展性。

### AMD对于E级超算的展望

系统包括硬件资源和软件资源（编写、调优执行程序），组成架构如图所示

![image-20201111174008391](https://imagebag.oss-cn-chengdu.aliyuncs.com/img/image-20201111174008391.png)

- a：通过网络互连的机柜，通常包含数百个机柜
- b：机柜内部包括多个计算节点，包括计算资源和存储资源，顶部有交换机和IO处理机和系统管理设备
- c：基于硅介质的APU和多个3D架构的存储器，

通常a、b两个部分大同小异，主要能体现AMD计算平台的优势在于c的设计。

**APU采用通用高吞吐量管道**，实现性能和能源效率的平衡，结合了高性能多核CPU，提升单线程处理水平。其设计思路是，GPU实现大规模、高吞吐量的计算，CPU实现那些难以并行处理的程序，并为历史遗留软件提供支持（这部分软件难以并行化）。AMD异构平台还包括内存的异构，**通过结合DRAM和NVM实现高带宽和低耗能**，Heterogeneous System Architecture（HSA）异构平台通过网络**network interface controller（NIC高带宽、低开销）**与其他节点互联，并对外提供完整的、易于访问的硬件和软件接口（生态系统），以使编程人员能够有效发挥超算机的最大效能。

### APU架构——实现异构计算

异构APU方法提供了高吞吐量、高效的GPU资源与为单线程性能而优化的CPU。

异构平台提供了一个统一的虚拟内存空间，这样CPU、GPU快速的传输数据（交换指针），从而避免了昂贵的操作（PCIE传输、数据格式重新编码，内存分配等）。以往的异构计算，所有的控制流都需要经过CPU，使得CPU及其传输通道成为了瓶颈，而AMD提供了硬件级的任务队列，使得GPU可以直接取得任务并生成执行线程，避免了与CPU的交互，同时提升了编程效率。传统的GPU异构计算中，所有的控制都必须经过CPU，限制了并行处理能力**（对比英伟达的CUDA计算模型）**

图中c部分提供了大量的计算单元，以提供10Tflops的持续处理能力，集成的3D-DRAM架构提供了大部分的内存带宽，将计算单元和内存单元存放在一个基板上，以提供高带宽、低延迟和节能的访存模型。

设想的其他设计方案，将CPU抽离出来，单独组装一个节点，提供类似传统PC的编程环境，简化软件开发工（但这样每瓦性能无法达到要求）；使用外部GPU扩充计算资源，相较于传统的CPU、GPU松耦合的离散计算模型，将CPU-GPU集成起来的优势在于：

1. 降低数据传输的能耗、延迟
2. 更容易动态切换功耗，检测此时何种计算占主要部分，并动态调整功耗给优先级高的进程
3. 避免显示的同步操作（如消息发送、接受），降低编程复杂性
4. 更高的性能/面积比

E级计算机为充分实现其价值，不能仅针对特定应用的计算。

APU中的CPU和GPU共享存储系统，因此需要提供统一地址空间和同步机制，然而传统的地址空间编址和一致性协议仍包含较大的通信开销，**因此提出了一种新的同步机制QuickRelease**，实现了GPU线程间的轻量级同步。另外，定义了**内存一致性模型框架HRF**，给编程人员提供了良好的管理内存空间的工具。提出了**异构系统一致性协议HSC**，在区域上（如1KB）管理一致性，而不是缓存块上（64B）管理一致性。上述三种方法大大提高了APU的运行效率。

### 异构的内存模型

内存容量和带宽大小十分重要，美国能源部对E级超算的要求：每个节点提供4TB的带宽大小，1Tb的存储容量。但普遍认为容量目标难以实现。例如：JEDEC高带宽内存HBM标准，3D堆叠内存架构，每层提供128GB的访问带宽，一共8层，可以到达1tB访问带宽，同时增加信号速率、总线宽度和信道数量可能会将该结果推到所需的4 TBps。然而HBM的每层只能提供2Gb的，8层一共是16Gb，里1Tb的目标存储容量差16倍，即使再增加存储密度也很难实现1Tb的存储容量。

为了实现达到存储容量和通信速率要求，**采取两层存储架构模型，**第一层集中在片上，采用3D-stack模型，提供了128GB的存储容量和4TB的通信速率；第二层封装在片外，采用NVM技术，提供大容量存储介质。这种异构内存模型提供了：高带宽、低能耗的每秒内存访问（第一层）；大容量的存储介质（第二层）由于有了两层存储介质，因此导致了一个问题，即对内存的访问应当控制在第几层。第一层：后备存储器对编程人员透明。第二层：后备存储器由编程人员管理，对数据的放置完全控制。

然而，如此巨大的内存存储和访问，导致了功耗的增加，几乎占据了E级计算机整体功耗的一半。为了降低内存访问功耗，**提出将计算移动到数据部分上即processing in memory（PIM）**，这样就可以将处理器的频率略微降低，以实现低功耗技术，不过在3D-stack架构上进行资源计算带来了全新的挑战。

### 编程挑战

基于目前探讨的10w个节点的E级计算机，其包含了异构的APU结构、异构的内存模型、PIM功能、动态功耗管理和设备管理，因此编程人员不光要熟练代码编写，还应清楚整个系统的架构，这带来了不小的挑战。即使如此，仍然需要朝着这个方向努力，因为现存的GPU计算模型仍然需要通过CPU的调度，且无法直接与内存交互数据。而HSA提供了共享的内存空间和硬件级的任务调度队列，因此其潜在的计算性能高于现在的GPU计算环境。

传统的GPU编程需要从计算任务中提取出并行性，而AMD正寻求改进，对于每个可并行的计算部分，必须结合CPU和GPU结构。同时开发运行时增强功能，以实现将计算映射到不同的数据资源上(PIM)，提供性能，并降低功耗。

实现PIM和内存处理器间的缓存一致性有如下几个优势：

1. 易于调试、分析内存处理器上的代码
2. 可以灵活的选择将哪些计算代码移动到哪些计算资源上，而不需要显示的在内存中移动数据
3. 通过动态监测，可以优化计算和存储资源，自动的调整计算部分。

### 物理环境约束

功耗、散热、建筑结构等

这里主要关心功耗问题，由于APU采用了紧耦合架构，因此其中组件的联结、过程交互将对功耗、热能产生带来显著的影响，基于物理的不对称性，造成了性能和功耗的不对称性。对于运行时设备指标的监管可以改善这个状况，并将监控模块与电源管理模块整合在一块，以实现节点级，甚至是片上级组件的功率协调，以提高能效。

### 容错技术

在HAS系统中引入并行计算，需要考虑新的容错检测技术和纠正技术，针对E级系统可靠性研究应该解决两个主要目标：最小化节点中错误的发生的频率和降低纠错的成本。通过故障检测、恢复技术提高系统的RAS（reliability, availability, and serviceability）指标。

